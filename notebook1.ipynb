{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Février 2026)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif du projet\n",
    "Conformément au sujet, l'objectif est d'imaginer et tester des indicateurs quantitatifs du risque de réidentification (Inférence, Corrélation, Individualisation) sur des bases de données synthétiques[cite: 3, 30].\n",
    "\n",
    "Nous analyserons l'évolution du risque en fonction :\n",
    "1. Du **niveau de mélange** (shuffling) des données.\n",
    "2. De la **quantité d'informations** disponibles (scénarios de connaissance croissante).\n",
    "3. De la nature de la base (**Directe** vs **Échantillonnée**).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration pour la reproductibilité\n",
    "np.random.seed(2026)\n",
    "random.seed(2026)\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Simulation des Données (Connaissances Externes)\n",
    "\n",
    "Comme les fichiers sources ne sont pas fournis physiquement, nous générons la base `connaissances_externes.txt` en respectant strictement la description des variables du PDF [cite: 6-18].\n",
    "\n",
    "**Variables générées :**\n",
    "* `id_sejour` : Identifiant (pour vérification uniquement)[cite: 9].\n",
    "* `age`, `age5`, `age10` : Précisions croissantes[cite: 10].\n",
    "* `sexe`[cite: 11].\n",
    "* Dates (`ymd`, `ym`, `y`) pour entrée et sortie[cite: 13, 14].\n",
    "* Variables médicales (Target) : `liste_diag`, `liste_acte` (variables barrées/inconnues à inférer)[cite: 8, 17, 18]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n_rows=1000):\n",
    "    data = {}\n",
    "    # 1. Identifiant\n",
    "    data['id_sejour'] = np.arange(1, n_rows + 1)\n",
    "    \n",
    "    # 2. Démographie avec précisions croissantes\n",
    "    ages = np.random.randint(0, 100, n_rows)\n",
    "    data['age'] = ages\n",
    "    data['age5'] = (ages // 5) * 5  # Arrondi à 5 ans\n",
    "    data['age10'] = (ages // 10) * 10 # Arrondi à 10 ans\n",
    "    data['sexe'] = np.random.choice(['M', 'F'], n_rows)\n",
    "    \n",
    "    # 3. Dates avec précisions croissantes\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    dates_entree = [start_date + timedelta(days=np.random.randint(0, 365*3)) for _ in range(n_rows)]\n",
    "    durees = np.random.randint(1, 20, n_rows)\n",
    "    dates_sortie = [d + timedelta(days=int(dur)) for d, dur in zip(dates_entree, durees)]\n",
    "    \n",
    "    # Formatage Entrée\n",
    "    data['entree_date_ymd'] = [d.strftime('%Y-%m-%d') for d in dates_entree]\n",
    "    data['entree_date_ym'] = [d.strftime('%Y-%m') for d in dates_entree]\n",
    "    data['entree_date_y'] = [d.strftime('%Y') for d in dates_entree]\n",
    "    \n",
    "    # Formatage Sortie\n",
    "    data['sortie_date_ymd'] = [d.strftime('%Y-%m-%d') for d in dates_sortie]\n",
    "    data['sortie_date_ym'] = [d.strftime('%Y-%m') for d in dates_sortie]\n",
    "    data['sortie_date_y'] = [d.strftime('%Y') for d in dates_sortie]\n",
    "    \n",
    "    # 4. Modes et Spécialités\n",
    "    data['entree_mode'] = np.random.choice(['Urgence', 'Prog', 'Transfert'], n_rows)\n",
    "    data['sortie_mode'] = np.random.choice(['Domicile', 'Transfert', 'Deces'], n_rows)\n",
    "    data['specialite'] = np.random.choice(['MCO', 'CHIR', 'PSY', 'OBST'], n_rows)\n",
    "    data['chirurgie'] = np.random.choice([0, 1], n_rows)\n",
    "    \n",
    "    # 5. Pathologies (Variables sensibles à inférer)\n",
    "    # Ces variables correspondent aux \"variables barrées\" du sujet (CIM10, CCAM, pathologies)\n",
    "    # Pour simplifier l'inférence, on utilise une cible binaire 'diabete'\n",
    "    data['diabete'] = np.random.choice([0, 1], n_rows, p=[0.9, 0.1])\n",
    "    data['liste_diag'] = [f\"CIM_{np.random.randint(100, 999)}\" for _ in range(n_rows)]\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Mélange aléatoire de l'ordre des colonnes (sauf id_sejour pour lisibilité) [cite: 20]\n",
    "    cols = list(df.columns)\n",
    "    cols.remove('id_sejour')\n",
    "    np.random.shuffle(cols)\n",
    "    return df[['id_sejour'] + cols]\n",
    "\n",
    "df_reference = generate_dataset(2000)\n",
    "print(\"Aperçu de connaissances_externes.txt :\")\n",
    "display(df_reference.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Génération des fichiers \"out_direct\" et \"out_sample\"\n",
    "\n",
    "Nous implémentons ici la logique de perturbation décrite dans le sujet :\n",
    "1.  **out_direct_XX** : Même population, mais XX% des cellules de chaque colonne sont mélangées.\n",
    "2.  **out_sample_XX** : Tirage avec remise (bootstrap), puis mélange de XX% des cellules.\n",
    "\n",
    "*Note : L'identifiant `id_sejour` est conservé pour vérifier le succès de la réidentification, mais ne sera pas utilisé comme clé de jointure par l'attaquant[cite: 28].*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_shuffle(df_input, percentage):\n",
    "    \"\"\"Mélange XX% des valeurs pour chaque colonne indépendamment.\"\"\"\n",
    "    df = df_input.copy()\n",
    "    n_rows = len(df)\n",
    "    n_shuffle = int(n_rows * (percentage / 100))\n",
    "    \n",
    "    if n_shuffle == 0:\n",
    "        return df\n",
    "        \n",
    "    for col in df.columns:\n",
    "        if col == 'id_sejour': continue  # On ne mélange pas l'ID pour pouvoir vérifier le résultat\n",
    "        \n",
    "        # Sélection des indices à mélanger\n",
    "        indices_to_shuffle = np.random.choice(df.index, n_shuffle, replace=False)\n",
    "        values = df.loc[indices_to_shuffle, col].values\n",
    "        np.random.shuffle(values)\n",
    "        df.loc[indices_to_shuffle, col] = values\n",
    "    return df\n",
    "\n",
    "def generate_variants(df_ref, levels=[0, 10, 20, 50]):\n",
    "    datasets = {}\n",
    "    \n",
    "    for lvl in levels:\n",
    "        # 1. OUT DIRECT : Population identique, mélange par colonne\n",
    "        datasets[f'out_direct_{lvl}'] = apply_shuffle(df_ref, lvl)\n",
    "        \n",
    "        # 2. OUT SAMPLE : Tirage avec remise, puis mélange\n",
    "        # Tirage avec remise de taille N\n",
    "        df_sample = df_ref.sample(n=len(df_ref), replace=True).reset_index(drop=True)\n",
    "        datasets[f'out_sample_{lvl}'] = apply_shuffle(df_sample, lvl)\n",
    "        \n",
    "    return datasets\n",
    "\n",
    "variants = generate_variants(df_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Définition des Indicateurs (Critères G29)\n",
    "\n",
    "Nous implémentons deux indicateurs principaux[cite: 30, 32]:\n",
    "\n",
    "1.  **Taux d'Individualisation (Réidentification)** : Capacité à isoler un enregistrement unique dans la base publiée et à le lier correctement à la base de connaissances.\n",
    "    * *Méthode* : On cherche les lignes uniques sur les quasi-identifiants dans la base publique. Si cette combinaison est unique, on regarde si l'`id_sejour` correspond à celui de la base de référence.\n",
    "2.  **Taux d'Inférence (Précision)** : Capacité à déduire une valeur sensible (ici `diabete` ou `liste_diag`) à partir des quasi-identifiants.\n",
    "    * *Méthode* : Si je réidentifie une personne (correctement ou non), quelle est la probabilité que la valeur sensible associée soit la vraie ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk(df_connaissance, df_publie, quasi_identifiers, sensitive_col='diabete'):\n",
    "    \"\"\"\n",
    "    Calcule les métriques de risque.\n",
    "    df_connaissance : Ce que l'attaquant sait (connaissances_externes.txt)\n",
    "    df_publie : Le fichier attaqué (out_direct ou out_sample)\n",
    "    qi : Liste des variables connues (scénario)\n",
    "    \"\"\"\n",
    "    # On joint sur les quasi-identifiants\n",
    "    # Note : Dans out_sample, un individu peut apparaître 0, 1 ou N fois.\n",
    "    \n",
    "    # 1. Isoler les combinaisons uniques dans le jeu publié (Individualisation potentielle)\n",
    "    # L'attaquant cible les lignes qui semblent uniques\n",
    "    counts = df_publie.groupby(quasi_identifiers).size()\n",
    "    unique_combinations = counts[counts == 1].index\n",
    "    \n",
    "    if len(unique_combinations) == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Filtrer le dataset publié pour ne garder que les uniques\n",
    "    # Astuce pandas pour filtrer sur multi-index\n",
    "    df_pub_unique = df_publie.set_index(quasi_identifiers)\n",
    "    df_pub_unique = df_pub_unique[df_pub_unique.index.isin(unique_combinations)].reset_index()\n",
    "    \n",
    "    # Tentative de lien avec la base de connaissance (Attaque)\n",
    "    # On regarde si pour ces combinaisons, on retrouve le bon ID\n",
    "    merged = pd.merge(\n",
    "        df_pub_unique, \n",
    "        df_connaissance, \n",
    "        on=quasi_identifiers, \n",
    "        how='inner', \n",
    "        suffixes=('_pub', '_know')\n",
    "    )\n",
    "    \n",
    "    if len(merged) == 0:\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    # --- Indicateur 1 : Individualisation Correcte ---\n",
    "    # Succès si l'ID caché est le même (preuve que c'est le bon séjour)\n",
    "    # Note : Le sujet dit \"l'identifiant... peut servir pour tester si une réidentification a réussi\" [cite: 28]\n",
    "    reid_success = merged[merged['id_sejour_pub'] == merged['id_sejour_know']]\n",
    "    risk_reid = len(reid_success) / len(df_publie) * 100  # % de la base totale réidentifiée\n",
    "    \n",
    "    # --- Indicateur 2 : Inférence Exacte ---\n",
    "    # Même si l'ID est faux (collision), est-ce que la valeur sensible est la même ?\n",
    "    # (L'attaquant se fiche de l'ID, il veut savoir si la personne a le diabète)\n",
    "    inference_success = merged[merged[f'{sensitive_col}_pub'] == merged[f'{sensitive_col}_know']]\n",
    "    risk_inference = len(inference_success) / len(merged) * 100 # Précision de l'attaque\n",
    "    \n",
    "    return risk_reid, risk_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exécution des Scénarios de \"Connaissance Croissante\"\n",
    "\n",
    "Le sujet demande de tester différents scénarios. Nous définissons 3 niveaux :\n",
    "1.  **Faible** : Âge flou (10 ans), Sexe, Année.\n",
    "2.  **Moyen** : Âge (5 ans), Sexe, Date (Mois), Spécialité.\n",
    "3.  **Fort** : Âge exact, Sexe, Date exacte (Jour), Spécialité, Mode entrée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    '1_Faible': ['age10', 'sexe', 'entree_date_y'],\n",
    "    '2_Moyen': ['age5', 'sexe', 'entree_date_ym', 'specialite'],\n",
    "    '3_Fort': ['age', 'sexe', 'entree_date_ymd', 'specialite', 'entree_mode']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, df_var in variants.items():\n",
    "    file_type = 'Direct' if 'direct' in name else 'Sample'\n",
    "    shuffle_level = int(name.split('_')[-1])\n",
    "    \n",
    "    for scen_name, cols in scenarios.items():\n",
    "        r_reid, r_inf = calculate_risk(df_reference, df_var, cols)\n",
    "        \n",
    "        results.append({\n",
    "            'Type': file_type,\n",
    "            'Mélange (%)': shuffle_level,\n",
    "            'Scénario': scen_name,\n",
    "            'Nb_Variables': len(cols),\n",
    "            'Risque_Reid (%)': r_reid,\n",
    "            'Risque_Inference (%)': r_inf\n",
    "        })\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "display(df_res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Présentation des Résultats et Discussion\n",
    "\n",
    "Nous visualisons l'évolution du risque en fonction du niveau de mélange et du scénario, comme demandé[cite: 33]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(metric, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    # Séparation Direct vs Sample via style de ligne ou facet\n",
    "    sns.lineplot(\n",
    "        data=df_res, \n",
    "        x='Mélange (%)', \n",
    "        y=metric, \n",
    "        hue='Scénario', \n",
    "        style='Type', \n",
    "        markers=True, \n",
    "        dashes=True\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.ylim(-5, 105)\n",
    "    plt.show()\n",
    "\n",
    "# Graphique 1 : Risque de Réidentification (Individualisation)\n",
    "plot_results('Risque_Reid (%)', 'Risque de Réidentification vs Mélange')\n",
    "\n",
    "# Graphique 2 : Risque d'Inférence (Précision de l'attribut sensible)\n",
    "plot_results('Risque_Inference (%)', \"Précision de l'Inférence (Diabète) vs Mélange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion des résultats [cite: 37]\n",
    "\n",
    "1.  **Impact du Scénario (Connaissance croissante)** :\n",
    "    * Plus le nombre et la précision des variables connues augmentent (Scénario Fort), plus le risque de réidentification est élevé (proche de 100% sans mélange).\n",
    "    * Les variables précises (Date jour vs Année) augmentent drastiquement l'unicité des individus.\n",
    "\n",
    "2.  **Impact du Mélange (Shuffle)** :\n",
    "    * Le mélange des colonnes casse les corrélations entre les quasi-identifiants. Le risque de réidentification chute linéairement avec le taux de mélange.\n",
    "    * Cependant, le risque d'inférence (deviner le diabète) peut rester élevé même si la réidentification exacte chute, car la distribution globale de la variable sensible reste inchangée dans la colonne.\n",
    "\n",
    "3.  **Direct vs Sample** :\n",
    "    * Les fichiers `out_sample` (tirage avec remise) présentent généralement un risque plus faible ou plus incertain que `out_direct`.\n",
    "    * **Raison** : L'échantillonnage introduit une incertitude fondamentale. Un individu de la base de connaissance peut ne pas être dans la base échantillonnée (risque nul), ou y être plusieurs fois (ambiguïté), rendant l'attaque plus difficile que sur la population complète."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
