{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Février 2026)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif du projet\n",
    "Conformément au sujet, l'objectif est d'imaginer et tester des indicateurs quantitatifs du risque de réidentification sur des bases de données de santé.\n",
    "\n",
    "Nous analysons les 3 critères du G29 (CNIL) :\n",
    "1.  **Individualisation** : Peut-on isoler un individu ?\n",
    "2.  **Inférence** : Peut-on déduire une information sensible ?\n",
    "3.  **Corrélation** : Peut-on lier des ensembles de données (conservation de la structure) ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Configuration graphique\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données\n",
    "\n",
    "Chargement de la base de référence et des fichiers variants (`out_direct` et `out_sample`) depuis le répertoire `projets_donnees`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire des données\n",
    "DATA_DIR = \"projets_donnees\"\n",
    "\n",
    "def load_data(directory):\n",
    "    data = {}\n",
    "    \n",
    "    # 1. Chargement de la base de référence\n",
    "    ref_path = os.path.join(directory, \"connaissances_externes.txt\")\n",
    "    if os.path.exists(ref_path):\n",
    "        data['reference'] = pd.read_csv(ref_path, sep=None, engine='python')\n",
    "        print(f\"Base référence chargée : {len(data['reference'])} lignes\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Le fichier {ref_path} est introuvable.\")\n",
    "\n",
    "    # 2. Chargement des fichiers variants\n",
    "    pattern = os.path.join(directory, \"out_*.txt\")\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Attention : Aucun fichier 'out_*.txt' trouvé.\")\n",
    "\n",
    "    for filepath in files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        name_key = filename.replace('.txt', '') # ex: out_direct_10\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=None, engine='python')\n",
    "            data[name_key] = df\n",
    "            print(f\" -> Chargé : {name_key} ({len(df)} lignes)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de {filename} : {e}\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "# Exécution du chargement\n",
    "datasets = load_data(DATA_DIR)\n",
    "df_reference = datasets['reference']\n",
    "\n",
    "# Aperçu des colonnes disponibles\n",
    "print(\"Colonnes disponibles :\", df_reference.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Définition des Indicateurs (G29) et Méthodologie\n",
    "\n",
    "Nous définissons ici les trois indicateurs demandés par la CNIL (G29), en explicitant la méthode de calcul utilisée pour chacun.\n",
    "\n",
    "### 3.1 Risque d'Individualisation (Taux de Réidentification)\n",
    "**Technique utilisée : Simulation d'une \"Attaque Procureur\" (Prosecutor Attack)**\n",
    "\n",
    "Cette technique simule un attaquant qui connaît des informations spécifiques sur une personne cible (les quasi-identifiants : Âge, Sexe, Date, etc.) et cherche à savoir si cette personne est unique dans la base de données.\n",
    "\n",
    "* **Méthodologie :**\n",
    "    1.  **Isolation des uniques ($k=1$) :** Dans le fichier *publié*, nous regroupons les lignes par combinaison de quasi-identifiants (QI). Nous ne gardons que les lignes qui sont **uniques** (qui n'apparaissent qu'une seule fois).\n",
    "    2.  **Appariement (Matching) :** Nous effectuons une jointure entre ces lignes uniques et la *base de référence* sur les mêmes colonnes QI.\n",
    "    3.  **Vérification (Vérité Terrain) :** Nous comparons l'`id_sejour`. Si l'ID du fichier publié correspond à l'ID du fichier de référence, l'individualisation est réussie.\n",
    "* **Formule :**\n",
    "    $$\\text{Taux} = \\frac{\\text{Nombre de correspondances uniques correctes}}{\\text{Taille totale de la base publiée}} \\times 100$$\n",
    "\n",
    "### 3.2 Risque d'Inférence (Déduction d'attribut sensible)\n",
    "**Technique utilisée : Mesure de la Précision de l'Attribut (Attribute Disclosure Accuracy)**\n",
    "\n",
    "L'objectif est de deviner une information sensible (ici `liste_diag`) avec certitude. Même si l'individualisation échoue (confusion entre deux personnes), l'inférence peut réussir si les deux personnes partagent la même maladie.\n",
    "\n",
    "* **Méthodologie :**\n",
    "    1.  **Lien par Quasi-Identifiants :** On lie les lignes de la base publiée à la base de référence via les variables connues.\n",
    "    2.  **Comparaison de la valeur sensible :** On compare la valeur trouvée dans le fichier publié avec la vraie valeur dans le fichier de référence.\n",
    "    3.  **Calcul de succès :** Une inférence est considérée comme réussie si la valeur est identique, *indépendamment de l'identifiant*.\n",
    "\n",
    "### 3.3 Risque de Corrélation (Linkability / Structure)\n",
    "**Technique utilisée : Comparaison de Matrices de Corrélation de Spearman**\n",
    "\n",
    "Le mélange par colonne vise à casser la structure des données. Cet indicateur mesure à quel point cette structure a survécu.\n",
    "\n",
    "* **Méthodologie :**\n",
    "    1.  **Encodage :** Les variables catégorielles sont factorisées pour le calcul.\n",
    "    2.  **Matrice de Spearman :** Nous calculons la corrélation de rang (Spearman) pour la base de référence ($M_{ref}$) et pour la base publiée ($M_{pub}$). *Spearman est préféré à Pearson pour les relations non linéaires et ordinales.*\n",
    "    3.  **Différence Moyenne :** Nous calculons la différence absolue moyenne entre les deux matrices.\n",
    "    4.  **Score :** $100 \\times (1 - \\text{Différence} \\times 2)$. Si la différence est 0, le risque est 100% (structure intacte)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_risk(df_ref, df_anon):\n",
    "    \"\"\"Calcule la conservation de la structure de corrélation (0-100%).\"\"\"\n",
    "    common_cols = [c for c in df_ref.columns if c in df_anon.columns and c != 'id_sejour']\n",
    "    if not common_cols: return 0.0\n",
    "    \n",
    "    # Encodage factoriel pour gérer les catégorielles et calcul Spearman\n",
    "    def get_encoded_corr(df, cols):\n",
    "        temp = pd.DataFrame()\n",
    "        for c in cols:\n",
    "            if df[c].dtype == 'object': temp[c] = pd.factorize(df[c])[0]\n",
    "            else: temp[c] = df[c]\n",
    "        return temp.corr(method='spearman')\n",
    "\n",
    "    corr_ref = get_encoded_corr(df_ref, common_cols).fillna(0)\n",
    "    corr_anon = get_encoded_corr(df_anon, common_cols).fillna(0)\n",
    "    \n",
    "    # Différence moyenne absolue\n",
    "    mean_diff = (corr_ref - corr_anon).abs().mean().mean()\n",
    "    \n",
    "    # Score : 100% si identique, diminue si différence augmente\n",
    "    return max(0, (1 - mean_diff * 2)) * 100\n",
    "\n",
    "def calculate_risk_metrics(df_connaissance, df_publie, quasi_identifiers, sensitive_col='liste_diag'):\n",
    "    \"\"\"\n",
    "    Calcule les 3 indicateurs : Individualisation, Inférence, Corrélation.\n",
    "    \"\"\"\n",
    "    # 1. Corrélation (Globale)\n",
    "    risk_corr = calculate_correlation_risk(df_connaissance, df_publie)\n",
    "\n",
    "    # Vérification colonnes\n",
    "    missing_cols = [c for c in quasi_identifiers if c not in df_publie.columns]\n",
    "    if missing_cols:\n",
    "        return 0.0, 0.0, risk_corr\n",
    "\n",
    "    # 2. Individualisation\n",
    "    # On groupe par QI pour trouver les uniques dans la base publiée\n",
    "    counts = df_publie.groupby(quasi_identifiers).size()\n",
    "    unique_combs = counts[counts == 1].index\n",
    "    \n",
    "    if len(unique_combs) == 0:\n",
    "        return 0.0, 0.0, risk_corr\n",
    "    \n",
    "    df_pub_unique = df_publie.set_index(quasi_identifiers)\n",
    "    df_pub_unique = df_pub_unique[df_pub_unique.index.isin(unique_combs)].reset_index()\n",
    "    \n",
    "    # Attaque par jointure avec la connaissance externe\n",
    "    merged = pd.merge(\n",
    "        df_pub_unique, \n",
    "        df_connaissance, \n",
    "        on=quasi_identifiers, \n",
    "        how='inner', \n",
    "        suffixes=('_pub', '_know')\n",
    "    )\n",
    "    \n",
    "    if len(merged) == 0: return 0.0, 0.0, risk_corr\n",
    "        \n",
    "    # Succès si l'ID d'origine est retrouvé (Vérité terrain)\n",
    "    reid_success = merged[merged['id_sejour_pub'] == merged['id_sejour_know']]\n",
    "    risk_reid = len(reid_success) / len(df_publie) * 100\n",
    "    \n",
    "    # 3. Inférence\n",
    "    # Si la variable sensible est présente dans la base, on compare sa valeur\n",
    "    if sensitive_col in df_publie.columns:\n",
    "        # Précision de la valeur sensible trouvée par l'attaquant\n",
    "        inf_success = merged[merged[f'{sensitive_col}_pub'] == merged[f'{sensitive_col}_know']]\n",
    "        risk_inference = len(inf_success) / len(merged) * 100\n",
    "    else:\n",
    "        risk_inference = 0.0\n",
    "    \n",
    "    return risk_reid, risk_inference, risk_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exécution des Scénarios\n",
    "\n",
    "Nous utilisons des scénarios de \"connaissance croissante\" incluant âges, dates, modes d'entrée/sortie et pathologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    '1_Faible': [\"age10\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_y\",\"sortie_date_y\"],\n",
    "    '2_Moyen': [\"age5\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_ym\",\"sortie_date_ym\",\"specialite\",\"chirurgie\"],\n",
    "    '3_Fort': [\"age\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_ymd\",\"sortie_date_ymd\",\"specialite\",\"chirurgie\",\"diabete\",\"insuffisance_renale\",\"demence\"]\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Cible pour l'inférence : 'liste_diag' (Diagnostics précis CIM10)\n",
    "TARGET_INFERENCE = 'liste_diag' \n",
    "\n",
    "for name, df_var in datasets.items():\n",
    "    if name == 'reference': continue\n",
    "    \n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        file_type = 'Direct' if 'direct' in name else 'Sample'\n",
    "        try: shuffle_level = int(parts[-1])\n",
    "        except: shuffle_level = 0\n",
    "    else: continue\n",
    "\n",
    "    for scen_name, cols in scenarios.items():\n",
    "        r_reid, r_inf, r_corr = calculate_risk_metrics(df_reference, df_var, cols, sensitive_col=TARGET_INFERENCE)\n",
    "        \n",
    "        results.append({\n",
    "            'Type': file_type,\n",
    "            'Mélange (%)': shuffle_level,\n",
    "            'Scénario': scen_name,\n",
    "            'Individualisation (%)': r_reid,\n",
    "            'Inférence (%)': r_inf,\n",
    "            'Corrélation (%)': r_corr\n",
    "        })\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "print(\"Aperçu des résultats :\")\n",
    "display(df_res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation et Analyse\n",
    "\n",
    "Comparaison des risques (Individualisation, Inférence, Corrélation) selon le niveau de mélange et le scénario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(df_res):\n",
    "    if df_res.empty:\n",
    "        print(\"Pas de données à afficher.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
    "    \n",
    "    # 1. Individualisation\n",
    "    sns.lineplot(data=df_res, x='Mélange (%)', y='Individualisation (%)', \n",
    "                 hue='Scénario', style='Type', markers=True, ax=axes[0])\n",
    "    axes[0].set_title(\"Risque d'Individualisation (Réidentification)\")\n",
    "    axes[0].set_ylim(-5, 105)\n",
    "\n",
    "    # 2. Inférence\n",
    "    sns.lineplot(data=df_res, x='Mélange (%)', y='Inférence (%)', \n",
    "                 hue='Scénario', style='Type', markers=True, ax=axes[1])\n",
    "    axes[1].set_title(f\"Risque d'Inférence (Cible: {TARGET_INFERENCE})\")\n",
    "    axes[1].set_ylim(-5, 105)\n",
    "\n",
    "    # 3. Corrélation\n",
    "    subset = df_res[df_res['Scénario'] == list(scenarios.keys())[0]]\n",
    "    sns.lineplot(data=subset, x='Mélange (%)', y='Corrélation (%)', \n",
    "                 style='Type', markers=True, ax=axes[2], color='green')\n",
    "    axes[2].set_title(\"Risque de Corrélation (Conservation Structure)\")\n",
    "    axes[2].set_ylim(-5, 105)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_metrics(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion et Discussion\n",
    "* **Individualisation** : Le scénario 3 (Fort), qui inclut des dates précises et des pathologies, montre un risque initial très élevé qui chute avec le mélange.\n",
    "* **Inférence** : La capacité à prédire `liste_diag` dépend fortement de la qualité de la réidentification. Une fois l'individu perdu, l'inférence devient aléatoire.\n",
    "* **Corrélation** : Cet indicateur montre à quel point la structure statistique de la base est détruite. Si le risque de corrélation est faible, la base perd aussi son utilité statistique pour les chercheurs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
