{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Février 2026)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif\n",
    "Ce notebook analyse les risques de réidentification sur des bases de données de santé synthétiques, selon les trois critères du G29 (CNIL) :\n",
    "1.  **Individualisation** : Capacité à isoler un individu.\n",
    "2.  **Inférence** : Capacité à déduire une information sensible inconnue.\n",
    "3.  **Corrélation** : Capacité à lier des données (conservation de la structure statistique).\n",
    "\n",
    "Nous comparons l'efficacité de l'anonymisation par mélange (shuffling) sur des fichiers directs et échantillonnés.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Configuration graphique\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données et de la Vérité Terrain\n",
    "\n",
    "Nous chargeons :\n",
    "1.  `connaissances_externes.txt` : La base de connaissance de l'attaquant.\n",
    "2.  `out_direct_0.txt` : La base originale non mélangée, qui servira de **Vérité Terrain (Ground Truth)** pour vérifier si les inférences de l'attaquant sont correctes.\n",
    "3.  Les fichiers variants (`out_direct_XX`, `out_sample_XX`) qui sont les bases publiées/attaquées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"projets_donnees\"\n",
    "\n",
    "def load_data(directory):\n",
    "    data = {}\n",
    "    \n",
    "    # 1. Chargement de la référence (Connaissances de l'attaquant)\n",
    "    ref_path = os.path.join(directory, \"connaissances_externes.txt\")\n",
    "    if os.path.exists(ref_path):\n",
    "        data['reference'] = pd.read_csv(ref_path, sep=None, engine='python')\n",
    "        print(f\"Base référence chargée : {len(data['reference'])} lignes\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Fichier manquant : {ref_path}\")\n",
    "\n",
    "    # 2. Chargement des fichiers publiés (Variants)\n",
    "    files = glob.glob(os.path.join(directory, \"out_*.txt\"))\n",
    "    if not files: print(\"Attention : Aucun fichier 'out_*.txt' trouvé.\")\n",
    "\n",
    "    for filepath in files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        name_key = filename.replace('.txt', '') # ex: out_direct_10\n",
    "        try:\n",
    "            data[name_key] = pd.read_csv(filepath, sep=None, engine='python')\n",
    "            print(f\" -> Chargé : {name_key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur {filename} : {e}\")\n",
    "    return data\n",
    "\n",
    "# Exécution du chargement\n",
    "datasets = load_data(DATA_DIR)\n",
    "df_reference = datasets['reference']\n",
    "\n",
    "# Définition de la Vérité Terrain pour vérifier l'Inférence\n",
    "# On utilise le fichier sans mélange (0%) pour connaitre les vraies maladies des patients\n",
    "if 'out_direct_0' in datasets:\n",
    "    df_truth = datasets['out_direct_0'].set_index('id_sejour')\n",
    "elif 'out_sample_0' in datasets:\n",
    "    df_truth = datasets['out_sample_0'].set_index('id_sejour')\n",
    "else:\n",
    "    df_truth = None\n",
    "    print(\"Attention : Pas de fichier '_0.txt' pour la vérité terrain. L'inférence sera à 0.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Méthodologie et Indicateurs\n",
    "\n",
    "### 3.1 Risque d'Individualisation (Taux de Réidentification)\n",
    "**Technique : Attaque par jointure sur les uniques**\n",
    "Nous simulons un attaquant qui cherche des individus uniques dans la base publiée.\n",
    "1.  Identification des lignes uniques sur les quasi-identifiants (QI) dans le fichier publié.\n",
    "2.  Jointure avec la base de connaissance.\n",
    "3.  Vérification via l'`id_sejour` (clé secrète). Si l'ID correspond, l'individu est réidentifié.\n",
    "\n",
    "### 3.2 Risque d'Inférence (Précision de l'attribut)\n",
    "**Technique : Comparaison avec la Vérité Terrain**\n",
    "L'attaquant devine la valeur d'une variable sensible (ex: `liste_diag`) à partir de la ligne qu'il a trouvée.\n",
    "1.  L'attaquant lit la valeur `liste_diag` dans le fichier publié mélangé.\n",
    "2.  Nous comparons cette valeur avec la **vraie** valeur issue du fichier `out_direct_0` (Vérité Terrain).\n",
    "3.  Si les valeurs sont identiques, l'inférence est réussie (le mélange n'a pas protégé cette info).\n",
    "\n",
    "### 3.3 Risque de Corrélation (Conservation de structure)\n",
    "**Technique : Corrélation de Spearman**\n",
    "Mesure si les liens statistiques entre les variables (ex: Âge vs Pathologie) sont préservés.\n",
    "1.  Calcul des matrices de corrélation de Spearman pour la référence et le fichier publié.\n",
    "2.  Calcul de la différence moyenne. Si la différence est faible, le risque est élevé (structure conservée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_risk(df_ref, df_anon):\n",
    "    \"\"\"Score de 0 à 100% indiquant la conservation de la structure des corrélations.\"\"\"\n",
    "    common_cols = [c for c in df_ref.columns if c in df_anon.columns and c != 'id_sejour']\n",
    "    if not common_cols: return 0.0\n",
    "    \n",
    "    # Encodage factoriel pour les variables catégorielles\n",
    "    def get_encoded_corr(df, cols):\n",
    "        temp = pd.DataFrame()\n",
    "        for c in cols:\n",
    "            if df[c].dtype == 'object': temp[c] = pd.factorize(df[c])[0]\n",
    "            else: temp[c] = df[c]\n",
    "        return temp.corr(method='spearman')\n",
    "\n",
    "    corr_ref = get_encoded_corr(df_ref, common_cols).fillna(0)\n",
    "    corr_anon = get_encoded_corr(df_anon, common_cols).fillna(0)\n",
    "    \n",
    "    # Différence moyenne\n",
    "    mean_diff = (corr_ref - corr_anon).abs().mean().mean()\n",
    "    return max(0, (1 - mean_diff * 2)) * 100\n",
    "\n",
    "def calculate_risk_metrics(df_connaissance, df_publie, quasi_identifiers, sensitive_col, df_truth_ref=None):\n",
    "    \"\"\"Calcule Individualisation, Inférence et Corrélation.\"\"\"\n",
    "    # 1. Corrélation (Globale)\n",
    "    risk_corr = calculate_correlation_risk(df_connaissance, df_publie)\n",
    "\n",
    "    # Vérification présence colonnes QI\n",
    "    if any(c not in df_publie.columns for c in quasi_identifiers): \n",
    "        return 0.0, 0.0, risk_corr\n",
    "\n",
    "    # 2. Individualisation\n",
    "    counts = df_publie.groupby(quasi_identifiers).size()\n",
    "    unique_combs = counts[counts == 1].index\n",
    "    \n",
    "    if len(unique_combs) == 0: return 0.0, 0.0, risk_corr\n",
    "    \n",
    "    # Filtrage des uniques et Jointure (Attaque)\n",
    "    df_pub_unique = df_publie.set_index(quasi_identifiers)\n",
    "    df_pub_unique = df_pub_unique[df_pub_unique.index.isin(unique_combs)].reset_index()\n",
    "    \n",
    "    merged = pd.merge(\n",
    "        df_pub_unique, df_connaissance, \n",
    "        on=quasi_identifiers, how='inner', suffixes=('_pub', '_know')\n",
    "    )\n",
    "    \n",
    "    if len(merged) == 0: return 0.0, 0.0, risk_corr\n",
    "        \n",
    "    reid_success = merged[merged['id_sejour_pub'] == merged['id_sejour_know']]\n",
    "    risk_reid = len(reid_success) / len(df_publie) * 100\n",
    "    \n",
    "    # 3. Inférence (Avec Vérité Terrain)\n",
    "    risk_inference = 0.0\n",
    "    \n",
    "    # On vérifie si la colonne sensible existe dans le fichier publié\n",
    "    if sensitive_col in df_publie.columns and df_truth_ref is not None:\n",
    "        if sensitive_col in df_truth_ref.columns:\n",
    "            # Nom de la colonne dans le merged (si conflit de nom, pandas a mis _pub, sinon nom original)\n",
    "            col_pub_name = f\"{sensitive_col}_pub\" if f\"{sensitive_col}_pub\" in merged.columns else sensitive_col\n",
    "            \n",
    "            # On compare : Valeur vue par l'attaquant VS Vraie valeur (via l'ID de la personne connue)\n",
    "            # L'ID de référence est 'id_sejour_know' (la personne que l'attaquant pense avoir trouvée)\n",
    "            try:\n",
    "                ids_suspects = merged['id_sejour_know']\n",
    "                # On ne garde que les IDs présents dans la vérité terrain\n",
    "                valid_mask = ids_suspects.isin(df_truth_ref.index)\n",
    "                \n",
    "                if valid_mask.any():\n",
    "                    subset_merged = merged[valid_mask]\n",
    "                    # Valeurs réelles pour ces patients\n",
    "                    true_values = df_truth_ref.loc[subset_merged['id_sejour_know']][sensitive_col].values\n",
    "                    # Valeurs observées dans le fichier mélangé\n",
    "                    observed_values = subset_merged[col_pub_name].values\n",
    "                    \n",
    "                    # Succès si égalité\n",
    "                    inf_success_count = np.sum(true_values == observed_values)\n",
    "                    risk_inference = inf_success_count / len(merged) * 100\n",
    "            except KeyError:\n",
    "                risk_inference = 0.0\n",
    "\n",
    "    return risk_reid, risk_inference, risk_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exécution des Scénarios\n",
    "\n",
    "Nous utilisons les scénarios définis, en ciblant la variable **`liste_diag`** pour mesurer le risque d'inférence (car `diabete` est déjà une variable connue dans le scénario Fort)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    '1_Faible': [\"age10\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_y\",\"sortie_date_y\"],\n",
    "    '2_Moyen': [\"age5\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_ym\",\"sortie_date_ym\",\"specialite\",\"chirurgie\"],\n",
    "    '3_Fort': [\"age\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_ymd\",\"sortie_date_ymd\",\"specialite\",\"chirurgie\",\"diabete\",\"insuffisance_renale\",\"demence\"]\n",
    "}\n",
    "\n",
    "# Variable cible pour l'inférence (Inconnue de l'attaquant dans les scénarios)\n",
    "TARGET_INFERENCE = 'liste_diag'\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, df_var in datasets.items():\n",
    "    if name == 'reference': continue\n",
    "    \n",
    "    # Extraction du niveau de mélange\n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        file_type = 'Direct' if 'direct' in name else 'Sample'\n",
    "        try: shuffle_level = int(parts[-1])\n",
    "        except: shuffle_level = 0\n",
    "    else: continue\n",
    "\n",
    "    for scen_name, cols in scenarios.items():\n",
    "        # Calcul des risques\n",
    "        r_reid, r_inf, r_corr = calculate_risk_metrics(\n",
    "            df_reference, \n",
    "            df_var, \n",
    "            cols, \n",
    "            sensitive_col=TARGET_INFERENCE,\n",
    "            df_truth_ref=df_truth\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            'Type': file_type,\n",
    "            'Mélange (%)': shuffle_level,\n",
    "            'Scénario': scen_name,\n",
    "            'Individualisation (%)': r_reid,\n",
    "            'Inférence (%)': r_inf,\n",
    "            'Corrélation (%)': r_corr\n",
    "        })\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "print(\"Calculs terminés.\")\n",
    "display(df_res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(df_res):\n",
    "    if df_res.empty:\n",
    "        print(\"Pas de données à afficher.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(22, 6))\n",
    "    \n",
    "    # 1. Individualisation\n",
    "    sns.lineplot(data=df_res, x='Mélange (%)', y='Individualisation (%)', \n",
    "                 hue='Scénario', style='Type', markers=True, ax=axes[0])\n",
    "    axes[0].set_title(\"Risque d'Individualisation (Réidentification)\")\n",
    "    axes[0].set_ylim(-5, 105)\n",
    "\n",
    "    # 2. Inférence\n",
    "    sns.lineplot(data=df_res, x='Mélange (%)', y='Inférence (%)', \n",
    "                 hue='Scénario', style='Type', markers=True, ax=axes[1])\n",
    "    axes[1].set_title(f\"Risque d'Inférence (Cible: {TARGET_INFERENCE})\")\n",
    "    axes[1].set_ylim(-5, 105)\n",
    "\n",
    "    # 3. Corrélation\n",
    "    # Filtre sur un seul scénario pour lisibilité (métrique globale)\n",
    "    subset = df_res[df_res['Scénario'] == list(scenarios.keys())[0]]\n",
    "    sns.lineplot(data=subset, x='Mélange (%)', y='Corrélation (%)', \n",
    "                 style='Type', markers=True, ax=axes[2], color='green')\n",
    "    axes[2].set_title(\"Risque de Corrélation (Conservation Structure)\")\n",
    "    axes[2].set_ylim(-5, 105)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_metrics(df_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
