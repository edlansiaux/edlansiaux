{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Février 2026)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif du projet\n",
    "Conformément au sujet, l'objectif est d'imaginer et tester des indicateurs quantitatifs du risque de réidentification (Inférence, Corrélation, Individualisation) sur des bases de données fournies.\n",
    "\n",
    "Nous analyserons l'évolution du risque en fonction :\n",
    "1. Du **niveau de mélange** (shuffling) des données.\n",
    "2. De la **quantité d'informations** disponibles (scénarios de connaissance croissante).\n",
    "3. De la nature de la base (**Directe** vs **Échantillonnée**).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Configuration graphique\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données\n",
    "\n",
    "Les fichiers sont stockés dans le répertoire `projets_donnees`.\n",
    "Nous chargeons :\n",
    "1. `connaissances_externes.txt` : La base de référence.\n",
    "2. Tous les fichiers `out_direct_*.txt` et `out_sample_*.txt` trouvés dans le dossier.\n",
    "\n",
    "**Note sur les variables  :**\n",
    "Les fichiers contiennent notamment : `id_sejour`, `age` (et variantes), `sexe`, `entree_date` (et variantes), `specialite`, `chirurgie`, `diabete`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire des données\n",
    "DATA_DIR = \"projets_donnees\"\n",
    "\n",
    "def load_data(directory):\n",
    "    data = {}\n",
    "    \n",
    "    # 1. Chargement de la base de référence\n",
    "    ref_path = os.path.join(directory, \"connaissances_externes.txt\")\n",
    "    if os.path.exists(ref_path):\n",
    "        # Utilisation de sep=None pour détection auto (csv, tsv, etc.)\n",
    "        data['reference'] = pd.read_csv(ref_path, sep=None, engine='python')\n",
    "        print(f\"Base référence chargée : {len(data['reference'])} lignes\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Le fichier {ref_path} est introuvable.\")\n",
    "\n",
    "    # 2. Chargement des fichiers variants (out_direct et out_sample)\n",
    "    # On cherche tous les fichiers commençant par 'out_' dans le dossier\n",
    "    pattern = os.path.join(directory, \"out_*.txt\")\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Attention : Aucun fichier 'out_*.txt' trouvé.\")\n",
    "\n",
    "    for filepath in files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        name_key = filename.replace('.txt', '') # ex: out_direct_10\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=None, engine='python')\n",
    "            data[name_key] = df\n",
    "            print(f\" -> Chargé : {name_key} ({len(df)} lignes)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de {filename} : {e}\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "# Exécution du chargement\n",
    "datasets = load_data(DATA_DIR)\n",
    "df_reference = datasets['reference']\n",
    "\n",
    "# Aperçu\n",
    "df_reference.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Définition des Indicateurs (Critères G29)\n",
    "\n",
    "Conformément aux instructions [cite: 30-32], nous définissons des indicateurs expérimentaux pour l'**Individualisation** et l'**Inférence**.\n",
    "\n",
    "1.  **Taux d'Individualisation (Réidentification)** : Capacité à isoler un enregistrement unique dans la base publiée et à le lier correctement à la base de connaissances via l'`id_sejour` (qui sert de vérité terrain [cite: 28]).\n",
    "2.  **Taux d'Inférence (Précision)** : Capacité à déduire une valeur sensible (ex: `diabete`) à partir des quasi-identifiants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_risk(df_connaissance, df_publie, quasi_identifiers, sensitive_col='diabete'):\n",
    "    \"\"\"\n",
    "    Calcule les métriques de risque en comparant la base de connaissance (source)\n",
    "    et la base publiée (attaquée).\n",
    "    \"\"\"\n",
    "    # Vérification que les colonnes existent dans les deux bases\n",
    "    missing_cols = [c for c in quasi_identifiers if c not in df_publie.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Colonnes manquantes dans le fichier publié : {missing_cols}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    # 1. Isoler les combinaisons uniques dans le jeu publié (Individualisation potentielle)\n",
    "    counts = df_publie.groupby(quasi_identifiers).size()\n",
    "    unique_combinations = counts[counts == 1].index\n",
    "    \n",
    "    if len(unique_combinations) == 0:\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    # Filtrer le dataset publié pour ne garder que les uniques\n",
    "    df_pub_unique = df_publie.set_index(quasi_identifiers)\n",
    "    df_pub_unique = df_pub_unique[df_pub_unique.index.isin(unique_combinations)].reset_index()\n",
    "    \n",
    "    # 2. Tentative de lien avec la base de connaissance (Attaque par jointure)\n",
    "    merged = pd.merge(\n",
    "        df_pub_unique, \n",
    "        df_connaissance, \n",
    "        on=quasi_identifiers, \n",
    "        how='inner', \n",
    "        suffixes=('_pub', '_know')\n",
    "    )\n",
    "    \n",
    "    if len(merged) == 0:\n",
    "        return 0.0, 0.0\n",
    "        \n",
    "    # --- Indicateur 1 : Individualisation Correcte ---\n",
    "    # Succès si l'ID caché est le même [cite: 28]\n",
    "    reid_success = merged[merged['id_sejour_pub'] == merged['id_sejour_know']]\n",
    "    risk_reid = len(reid_success) / len(df_publie) * 100\n",
    "    \n",
    "    # --- Indicateur 2 : Inférence Exacte ---\n",
    "    # Est-ce que la valeur sensible déduite est la bonne (même si l'ID est faux) ?\n",
    "    if sensitive_col in df_publie.columns and sensitive_col in df_connaissance.columns:\n",
    "        # On suppose que l'attaquant prend la valeur de la ligne unique trouvée\n",
    "        inference_success = merged[merged[f'{sensitive_col}_pub'] == merged[f'{sensitive_col}_know']]\n",
    "        risk_inference = len(inference_success) / len(merged) * 100\n",
    "    else:\n",
    "        risk_inference = 0.0\n",
    "    \n",
    "    return risk_reid, risk_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exécution des Scénarios de \"Connaissance Croissante\"\n",
    "\n",
    "Nous définissons 3 scénarios basés sur les variables listées dans le sujet [cite: 10-16] :\n",
    "1.  **Faible** : Âge imprécis (10 ans), Sexe, Année d'entrée.\n",
    "2.  **Moyen** : Âge moyen (5 ans), Sexe, Date (Mois), Spécialité.\n",
    "3.  **Fort** : Âge exact, Sexe, Date exacte (Jour), Spécialité, Mode entrée, Chirurgie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des scénarios selon les variables du PDF [cite: 10-16]\n",
    "scenarios = {\n",
    "    '1_Faible': ['age10', 'sexe', 'entree_date_y'],\n",
    "    '2_Moyen': ['age5', 'sexe', 'entree_date_ym', 'specialite'],\n",
    "    '3_Fort': ['age', 'sexe', 'entree_date_ymd', 'specialite', 'entree_mode', 'chirurgie']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, df_var in datasets.items():\n",
    "    if name == 'reference': continue\n",
    "    \n",
    "    # Extraction du type et du pourcentage depuis le nom du fichier (ex: out_direct_10)\n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        file_type = 'Direct' if 'direct' in name else 'Sample'\n",
    "        try:\n",
    "            shuffle_level = int(parts[-1])\n",
    "        except ValueError:\n",
    "            shuffle_level = 0 # Fallback si le nom ne finit pas par un chiffre\n",
    "    else:\n",
    "        continue # Fichier mal nommé\n",
    "\n",
    "    for scen_name, cols in scenarios.items():\n",
    "        # Calcul des risques pour ce fichier et ce scénario\n",
    "        r_reid, r_inf = calculate_risk(df_reference, df_var, cols, sensitive_col='diabete')\n",
    "        \n",
    "        results.append({\n",
    "            'Type': file_type,\n",
    "            'Mélange (%)': shuffle_level,\n",
    "            'Scénario': scen_name,\n",
    "            'Nb_Variables': len(cols),\n",
    "            'Risque_Reid (%)': r_reid,\n",
    "            'Risque_Inference (%)': r_inf\n",
    "        })\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "display(df_res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Présentation des Résultats et Discussion\n",
    "\n",
    "Visualisation de l'évolution des risques en fonction du mélange et des connaissances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(metric, title):\n",
    "    if df_res.empty:\n",
    "        print(\"Aucun résultat à afficher. Vérifiez le chargement des fichiers.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(\n",
    "        data=df_res, \n",
    "        x='Mélange (%)', \n",
    "        y=metric, \n",
    "        hue='Scénario', \n",
    "        style='Type', \n",
    "        markers=True, \n",
    "        dashes=True\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.ylabel(metric)\n",
    "    plt.ylim(-5, 105)\n",
    "    plt.show()\n",
    "\n",
    "# Graphique 1 : Risque d'Individualisation\n",
    "plot_results('Risque_Reid (%)', 'Risque de Réidentification vs Mélange')\n",
    "\n",
    "# Graphique 2 : Risque d'Inférence\n",
    "plot_results('Risque_Inference (%)', \"Précision de l'Inférence (Diabète) vs Mélange\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion des résultats attendus\n",
    "\n",
    "1.  **Impact du Mélange** : On s'attend à ce que le risque chute drastiquement à mesure que le pourcentage de mélange augmente (les lignes deviennent des composites artificiels qui ne correspondent plus à la référence).\n",
    "2.  **Impact des Connaissances** : Plus le scénario est \"Fort\" (plus de variables précises), plus le risque de réidentification est élevé à faible taux de mélange.\n",
    "3.  **Direct vs Sample** : La méthode \"Sample\" (tirage avec remise) devrait offrir une meilleure protection (risque plus faible) car elle introduit une incertitude sur la présence de l'individu dans la base[cite: 26]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
