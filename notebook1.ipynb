{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Analyse Avancée)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif du projet\n",
    "Ce notebook propose une évaluation approfondie des risques de réidentification en confrontant plusieurs méthodologies de mesure.\n",
    "\n",
    "Nous benchmarkons deux approches pour les critères clés :\n",
    "1.  **Corrélation** : Comparaison entre **Spearman** (rang) et **Cramer's V** (nominal).\n",
    "2.  **Inférence** : Comparaison entre le **Succès Réel** (vérifié par vérité terrain) et le **Risque Théorique** (basé sur l'homogénéité $l$-diversity).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Configuration graphique\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données\n",
    "Chargement de la base de référence et des fichiers variants depuis `projets_donnees`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"projets_donnees\"\n",
    "\n",
    "def load_data(directory):\n",
    "    data = {}\n",
    "    ref_path = os.path.join(directory, \"connaissances_externes.txt\")\n",
    "    if os.path.exists(ref_path):\n",
    "        data['reference'] = pd.read_csv(ref_path, sep=None, engine='python')\n",
    "        print(f\"Base référence chargée : {len(data['reference'])} lignes\")\n",
    "    \n",
    "    files = glob.glob(os.path.join(directory, \"out_*.txt\"))\n",
    "    for filepath in files:\n",
    "        name_key = os.path.basename(filepath).replace('.txt', '')\n",
    "        try:\n",
    "            data[name_key] = pd.read_csv(filepath, sep=None, engine='python')\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur {name_key} : {e}\")\n",
    "    return data\n",
    "\n",
    "datasets = load_data(DATA_DIR)\n",
    "df_reference = datasets['reference']\n",
    "\n",
    "# Vérité Terrain pour l'inférence réelle\n",
    "if 'out_direct_0' in datasets:\n",
    "    df_truth = datasets['out_direct_0'].set_index('id_sejour')\n",
    "elif 'out_sample_0' in datasets:\n",
    "    df_truth = datasets['out_sample_0'].set_index('id_sejour')\n",
    "else:\n",
    "    df_truth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Méthodologie Avancée et Comparaison\n",
    "\n",
    "### 3.1 Benchmark : Corrélation\n",
    "Le mélange des colonnes vise à détruire la structure de la base. Pour mesurer cette destruction, nous comparons deux méthodes :\n",
    "\n",
    "* **Méthode A : Spearman (Rang)**\n",
    "    * *Principe* : Transforme les catégories en nombres (0, 1, 2...) et mesure la corrélation d'ordre.\n",
    "    * *Limite* : Impose un ordre arbitraire aux données nominales (ex: 'Cardio' < 'Neuro'), ce qui peut créer de faux signaux de corrélation ou en masquer.\n",
    "\n",
    "* **Méthode B : Cramer's V (Nominal) [NOUVEAU]**\n",
    "    * *Principe* : Basé sur le test du Chi-2. Mesure la force d'association entre deux variables catégorielles sans notion d'ordre.\n",
    "    * *Avantage* : Beaucoup plus rigoureux pour des données médicales (CIM10, Spécialité, Sexe).\n",
    "\n",
    "### 3.2 Benchmark : Inférence\n",
    "L'inférence est la capacité à déduire une information sensible.\n",
    "\n",
    "* **Méthode A : Succès Réel (Vérité Terrain)**\n",
    "    * *Principe* : On vérifie si la valeur devinée est *réellement* la bonne en regardant le fichier original secret.\n",
    "    * *Sens* : Mesure la vulnérabilité réelle, \"Dieu voit tout\".\n",
    "\n",
    "* **Méthode B : Risque Théorique (Homogénéité) [NOUVEAU]**\n",
    "    * *Principe* : On regarde les groupes d'individus partageant les mêmes quasi-identifiants ($k$-anonymity groups). On calcule la diversité des maladies dans ces groupes.\n",
    "    * *Calcul* : Si dans un groupe de 3 personnes, tout le monde a le diabète, l'attaquant est sûr à 100% (Risque = 1). S'il y a 3 maladies différentes, il a 1 chance sur 3 (Risque = 0.33).\n",
    "    * *Sens* : Mesure la confiance de l'attaquant, sans avoir besoin de la vérité terrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FONCTIONS METRIQUES ---\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calcule le V de Cramer pour deux séries catégorielles.\"\"\"\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.sqrt(phi2 / min(k-1, r-1)) if min(k-1, r-1) > 0 else 0\n",
    "\n",
    "def calculate_structure_score(df_ref, df_anon, method='spearman'):\n",
    "    \"\"\"Compare les matrices de corrélation (Spearman ou Cramer).\"\"\"\n",
    "    common_cols = [c for c in df_ref.columns if c in df_anon.columns and c != 'id_sejour']\n",
    "    if not common_cols: return 0.0\n",
    "    \n",
    "    # 1. Calcul des matrices\n",
    "    if method == 'spearman':\n",
    "        # Factorisation simple pour Spearman\n",
    "        df1 = df_ref[common_cols].apply(lambda x: pd.factorize(x)[0])\n",
    "        df2 = df_anon[common_cols].apply(lambda x: pd.factorize(x)[0])\n",
    "        mat1 = df1.corr(method='spearman').fillna(0)\n",
    "        mat2 = df2.corr(method='spearman').fillna(0)\n",
    "    \n",
    "    elif method == 'cramer':\n",
    "        # Calcul coûteux : on itère sur les paires\n",
    "        mat1 = pd.DataFrame(index=common_cols, columns=common_cols, dtype=float)\n",
    "        mat2 = pd.DataFrame(index=common_cols, columns=common_cols, dtype=float)\n",
    "        \n",
    "        # Pour optimiser, on prend un sous-ensemble si trop de colonnes, ou on fait le calcul complet\n",
    "        # Ici calcul complet simplifié\n",
    "        for c1 in common_cols:\n",
    "            for c2 in common_cols:\n",
    "                if c1 == c2: \n",
    "                    mat1.loc[c1, c2] = 1.0\n",
    "                    mat2.loc[c1, c2] = 1.0\n",
    "                else:\n",
    "                    # On calcule Cramer uniquement si ce n'est pas déjà fait (symétrie)\n",
    "                    if pd.isna(mat1.loc[c2, c1]):\n",
    "                        val1 = cramers_v(df_ref[c1], df_ref[c2])\n",
    "                        mat1.loc[c1, c2] = mat1.loc[c2, c1] = val1\n",
    "                        val2 = cramers_v(df_anon[c1], df_anon[c2])\n",
    "                        mat2.loc[c1, c2] = mat2.loc[c2, c1] = val2\n",
    "    \n",
    "    # 2. Comparaison (Différence Moyenne)\n",
    "    diff = (mat1 - mat2).abs().mean().mean()\n",
    "    # Score : 100% = structure identique, 0% = structure détruite\n",
    "    return max(0, (1 - diff * 2)) * 100\n",
    "\n",
    "def calculate_advanced_metrics(df_connaissance, df_publie, qi, sensitive_col, df_truth):\n",
    "    # --- 1. Corrélation (Benchmark) ---\n",
    "    corr_spearman = calculate_structure_score(df_connaissance, df_publie, method='spearman')\n",
    "    # Note: Cramer peut être lent sur grosses bases, on le fait ici pour la démonstration\n",
    "    corr_cramer = calculate_structure_score(df_connaissance, df_publie, method='cramer')\n",
    "\n",
    "    if any(c not in df_publie.columns for c in qi):
