{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Février 2026)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif du projet\n",
    "Conformément au sujet, l'objectif est d'imaginer et tester des indicateurs quantitatifs du risque de réidentification sur des bases de données de santé.\n",
    "\n",
    "Nous analysons les 3 critères du G29 (CNIL) :\n",
    "1.  **Individualisation** : Peut-on isoler un individu ?\n",
    "2.  **Inférence** : Peut-on déduire une information sensible ?\n",
    "3.  **Corrélation** : Peut-on lier des ensembles de données (ou des attributs entre eux) ?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Configuration graphique\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données\n",
    "\n",
    "Chargement de la base de référence et des fichiers variants (`out_direct` et `out_sample`) depuis le répertoire `projets_donnees`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le répertoire des données\n",
    "DATA_DIR = \"projets_donnees\"\n",
    "\n",
    "def load_data(directory):\n",
    "    data = {}\n",
    "    \n",
    "    # 1. Chargement de la base de référence\n",
    "    ref_path = os.path.join(directory, \"connaissances_externes.txt\")\n",
    "    if os.path.exists(ref_path):\n",
    "        data['reference'] = pd.read_csv(ref_path, sep=None, engine='python')\n",
    "        print(f\"Base référence chargée : {len(data['reference'])} lignes\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Le fichier {ref_path} est introuvable.\")\n",
    "\n",
    "    # 2. Chargement des fichiers variants\n",
    "    pattern = os.path.join(directory, \"out_*.txt\")\n",
    "    files = glob.glob(pattern)\n",
    "    \n",
    "    if not files:\n",
    "        print(\"Attention : Aucun fichier 'out_*.txt' trouvé.\")\n",
    "\n",
    "    for filepath in files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        name_key = filename.replace('.txt', '') # ex: out_direct_10\n",
    "        try:\n",
    "            df = pd.read_csv(filepath, sep=None, engine='python')\n",
    "            data[name_key] = df\n",
    "            print(f\" -> Chargé : {name_key} ({len(df)} lignes)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur lors du chargement de {filename} : {e}\")\n",
    "            \n",
    "    return data\n",
    "\n",
    "# Exécution du chargement\n",
    "datasets = load_data(DATA_DIR)\n",
    "df_reference = datasets['reference']\n",
    "\n",
    "# Aperçu\n",
    "df_reference.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Définition des Indicateurs (G29)\n",
    "\n",
    "Nous définissons ici les trois indicateurs demandés.\n",
    "\n",
    "### 3.1 Individualisation (Réidentification)\n",
    "Capacité à isoler un enregistrement unique dans la base publiée et à le lier correctement à la base de connaissances.\n",
    "\n",
    "### 3.2 Inférence (Précision)\n",
    "Capacité à déduire une valeur sensible (ex: `diabete`) avec exactitude, même si l'identification formelle a échoué.\n",
    "\n",
    "### 3.3 Corrélation (Conservation de structure)\n",
    "Le mélange des colonnes (shuffling) vise à briser les liens entre les variables (ex: lien entre `Age` et `Pathologie`).\n",
    "* **Mesure** : Nous calculons la matrice de corrélation de la base de référence et celle de la base attaquée. Le risque de corrélation est élevé si les matrices sont similaires (la structure des liens est préservée).\n",
    "* **Formule** : Nous utilisons une similarité basée sur la différence moyenne des coefficients de corrélation (Pearson/Spearman)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_correlation_risk(df_ref, df_anon):\n",
    "    \"\"\"\n",
    "    Calcule le risque de corrélation en comparant les matrices de corrélation.\n",
    "    Retourne un score de 0 à 100% (100% = structure parfaitement conservée).\n",
    "    \"\"\"\n",
    "    # 1. Sélection et encodage des colonnes communes pour la corrélation\n",
    "    common_cols = [c for c in df_ref.columns if c in df_anon.columns and c != 'id_sejour']\n",
    "    \n",
    "    if not common_cols:\n",
    "        return 0.0\n",
    "    \n",
    "    # Pour gérer les variables catégorielles, on les factorise (encodage simple)\n",
    "    # Cela permet de voir si les liens statistiques sont maintenus\n",
    "    def get_encoded_matrix(df, cols):\n",
    "        temp_df = pd.DataFrame()\n",
    "        for c in cols:\n",
    "            if df[c].dtype == 'object':\n",
    "                temp_df[c] = pd.factorize(df[c])[0]\n",
    "            else:\n",
    "                temp_df[c] = df[c]\n",
    "        return temp_df.corr(method='spearman') # Spearman gère mieux les relations non linéaires/rangs\n",
    "\n",
    "    corr_ref = get_encoded_matrix(df_ref, common_cols)\n",
    "    corr_anon = get_encoded_matrix(df_anon, common_cols)\n",
    "    \n",
    "    # 2. Calcul de la différence moyenne absolue entre les matrices\n",
    "    # On remplace les NaN par 0 (cas de variance nulle)\n",
    "    diff_matrix = (corr_ref.fillna(0) - corr_anon.fillna(0)).abs()\n",
    "    mean_diff = diff_matrix.mean().mean()\n",
    "    \n",
    "    # 3. Score de risque : Si diff = 0, Risque = 100%. Si diff est grand, Risque diminue.\n",
    "    # Une différence moyenne de 0 signifie une corrélation parfaite avec l'original.\n",
    "    # Empiriquement, si la différence > 0.5, la structure est très cassée.\n",
    "    risk_score = max(0, (1 - mean_diff * 2)) * 100\n",
    "    \n",
    "    return risk_score\n",
    "\n",
    "def calculate_risk_metrics(df_connaissance, df_publie, quasi_identifiers, sensitive_col='diabete'):\n",
    "    \"\"\"\n",
    "    Calcule les 3 indicateurs : Individualisation, Inférence, Corrélation.\n",
    "    \"\"\"\n",
    "    # --- 1. Indicateur Corrélation (Global sur le fichier) ---\n",
    "    # Indépendant du scénario de QI, dépend de l'intégrité globale du fichier\n",
    "    risk_corr = calculate_correlation_risk(df_connaissance, df_publie)\n",
    "\n",
    "    # --- Préparation pour Individualisation/Inférence ---\n",
    "    missing_cols = [c for c in quasi_identifiers if c not in df_publie.columns]\n",
    "    if missing_cols:\n",
    "        return 0.0, 0.0, risk_corr\n",
    "\n",
    "    # Isoler les combinaisons uniques\n",
    "    counts = df_publie.groupby(quasi_identifiers).size()\n",
    "    unique_combinations = counts[counts == 1].index\n",
    "    \n",
    "    if len(unique_combinations) == 0:\n",
    "        return 0.0, 0.0, risk_corr\n",
    "    \n",
    "    df_pub_unique = df_publie.set_index(quasi_identifiers)\n",
    "    df_pub_unique = df_pub_unique[df_pub_unique.index.isin(unique_combinations)].reset_index()\n",
    "    \n",
    "    # Attaque par jointure\n",
    "    merged = pd.merge(\n",
    "        df_pub_unique, \n",
    "        df_connaissance, \n",
    "        on=quasi_identifiers, \n",
    "        how='inner', \n",
    "        suffixes=('_pub', '_know')\n",
    "    )\n",
    "    \n",
    "    if len(merged) == 0:\n",
    "        return 0.0, 0.0, risk_corr\n",
    "        \n",
    "    # --- 2. Indicateur Individualisation ---\n",
    "    reid_success = merged[merged['id_sejour_pub'] == merged['id_sejour_know']]\n",
    "    risk_reid = len(reid_success) / len(df_publie) * 100\n",
    "    \n",
    "    # --- 3. Indicateur Inférence ---\n",
    "    if sensitive_col in df_publie.columns and sensitive_col in df_connaissance.columns:\n",
    "        inference_success = merged[merged[f'{sensitive_col}_pub'] == merged[f'{sensitive_col}_know']]\n",
    "        risk_inference = len(inference_success) / len(merged) * 100\n",
    "    else:\n",
    "        risk_inference = 0.0\n",
    "    \n",
    "    return risk_reid, risk_inference, risk_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exécution des Scénarios\n",
    "\n",
    "Nous testons les scénarios \"Faible\", \"Moyen\" et \"Fort\" pour observer l'impact sur les 3 indicateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    '1_Faible': ['age10', 'sexe', 'entree_date_y'],\n",
    "    '2_Moyen': ['age5', 'sexe', 'entree_date_ym', 'specialite'],\n",
    "    '3_Fort': ['age', 'sexe', 'entree_date_ymd', 'specialite', 'entree_mode', 'chirurgie']\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, df_var in datasets.items():\n",
    "    if name == 'reference': continue\n",
    "    \n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        file_type = 'Direct' if 'direct' in name else 'Sample'\n",
    "        try: shuffle_level = int(parts[-1])\n",
    "        except: shuffle_level = 0\n",
    "    else: continue\n",
    "\n",
    "    for scen_name, cols in scenarios.items():\n",
    "        r_reid, r_inf, r_corr = calculate_risk_metrics(df_reference, df_var, cols, sensitive_col='diabete')\n",
    "        \n",
    "        results.append({\n",
    "            'Type': file_type,\n",
    "            'Mélange (%)': shuffle_level,\n",
    "            'Scénario': scen_name,\n",
    "            'Individualisation (%)': r_reid,\n",
    "            'Inférence (%)': r_inf,\n",
    "            'Corrélation (%)': r_corr\n",
    "        })\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation et Analyse\n",
    "\n",
    "Nous affichons les courbes pour les 3 critères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_metrics(df_res):\n",
    "    if df_res.empty:\n",
    "        print(\"Pas de données à afficher.\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "    \n",
    "    # 1. Individualisation\n",
    "    sns.lineplot(data=df_res, x='Mélange (%)', y='Individualisation (%)', \n",
    "                 hue='Scénario', style='Type', markers=True, ax=axes[0])\n",
    "    axes[0].set_title(\"Risque d'Individualisation\")\n",
    "    axes[0].set_ylim(-5, 105)\n",
    "\n",
    "    # 2. Inférence\n",
    "    sns.lineplot(data=df_res, x='Mélange (%)', y='Inférence (%)', \n",
    "                 hue='Scénario', style='Type', markers=True, ax=axes[1])\n",
    "    axes[1].set_title(\"Risque d'Inférence (Qualité de la donnée déduite)\")\n",
    "    axes[1].set_ylim(-5, 105)\n",
    "\n",
    "    # 3. Corrélation (Ne dépend pas du scénario QI, on moyenne ou on prend un scénario)\n",
    "    # On filtre sur un scénario pour éviter la superposition inutile (la métrique est globale)\n",
    "    subset = df_res[df_res['Scénario'] == list(scenarios.keys())[0]]\n",
    "    sns.lineplot(data=subset, x='Mélange (%)', y='Corrélation (%)', \n",
    "                 style='Type', markers=True, ax=axes[2], color='green')\n",
    "    axes[2].set_title(\"Risque de Corrélation (Conservation de structure)\")\n",
    "    axes[2].set_ylim(-5, 105)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_all_metrics(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interprétation des résultats\n",
    "\n",
    "1.  **Individualisation** : Devrait chuter drastiquement avec le mélange. Le fichier `Sample` présente généralement un risque plus faible grâce à l'incertitude du tirage.\n",
    "2.  **Inférence** : Même si l'individualisation est faible, l'inférence peut rester correcte autour de 50% (hasard) ou plus si la distribution de la variable sensible est déséquilibrée (ex: 90% non-diabétique), mais le mélange la dégrade.\n",
    "3.  **Corrélation** : C'est l'indicateur le plus sensible au mélange par colonne. \n",
    "    * À 0% de mélange, le risque est de 100% (les liens Âge <-> Pathologie sont intacts).\n",
    "    * Dès que le mélange augmente, la structure de la base s'effondre, rendant impossible l'analyse statistique fiable (perte d'utilité majeure)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
