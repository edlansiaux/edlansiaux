{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet M2 MIAS : Risque de réidentification (Analyse Avancée)\n",
    "\n",
    "**Auteur :** [Votre Nom]\n",
    "**Superviseur :** Pr Emmanuel Chazard\n",
    "\n",
    "## 1. Objectif du projet\n",
    "Ce notebook propose une évaluation approfondie des risques de réidentification en confrontant plusieurs méthodologies de mesure.\n",
    "\n",
    "Nous benchmarkons deux approches pour les critères clés :\n",
    "1.  **Corrélation** : Comparaison entre **Spearman** (rang) et **Cramer's V** (nominal).\n",
    "2.  **Inférence** : Comparaison entre le **Succès Réel** (vérifié par vérité terrain) et le **Risque Théorique** (basé sur l'homogénéité $l$-diversity).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Configuration graphique\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chargement des Données\n",
    "Chargement de la base de référence et des fichiers variants depuis `projets_donnees`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"projets_donnees\"\n",
    "\n",
    "def load_data(directory):\n",
    "    data = {}\n",
    "    ref_path = os.path.join(directory, \"connaissances_externes.txt\")\n",
    "    if os.path.exists(ref_path):\n",
    "        data['reference'] = pd.read_csv(ref_path, sep=None, engine='python')\n",
    "        print(f\"Base référence chargée : {len(data['reference'])} lignes\")\n",
    "    \n",
    "    files = glob.glob(os.path.join(directory, \"out_*.txt\"))\n",
    "    for filepath in files:\n",
    "        name_key = os.path.basename(filepath).replace('.txt', '')\n",
    "        try:\n",
    "            data[name_key] = pd.read_csv(filepath, sep=None, engine='python')\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur {name_key} : {e}\")\n",
    "    return data\n",
    "\n",
    "datasets = load_data(DATA_DIR)\n",
    "df_reference = datasets['reference']\n",
    "\n",
    "# Vérité Terrain pour l'inférence réelle\n",
    "if 'out_direct_0' in datasets:\n",
    "    df_truth = datasets['out_direct_0'].set_index('id_sejour')\n",
    "elif 'out_sample_0' in datasets:\n",
    "    df_truth = datasets['out_sample_0'].set_index('id_sejour')\n",
    "else:\n",
    "    df_truth = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Méthodologie Avancée et Comparaison\n",
    "\n",
    "### 3.1 Benchmark : Corrélation\n",
    "Le mélange des colonnes vise à détruire la structure de la base. Pour mesurer cette destruction, nous comparons deux méthodes :\n",
    "\n",
    "* **Méthode A : Spearman (Rang)**\n",
    "    * *Principe* : Transforme les catégories en nombres (0, 1, 2...) et mesure la corrélation d'ordre.\n",
    "    * *Limite* : Impose un ordre arbitraire aux données nominales (ex: 'Cardio' < 'Neuro'), ce qui peut créer de faux signaux de corrélation ou en masquer.\n",
    "\n",
    "* **Méthode B : Cramer's V (Nominal) [NOUVEAU]**\n",
    "    * *Principe* : Basé sur le test du Chi-2. Mesure la force d'association entre deux variables catégorielles sans notion d'ordre.\n",
    "    * *Avantage* : Beaucoup plus rigoureux pour des données médicales (CIM10, Spécialité, Sexe).\n",
    "\n",
    "### 3.2 Benchmark : Inférence\n",
    "L'inférence est la capacité à déduire une information sensible.\n",
    "\n",
    "* **Méthode A : Succès Réel (Vérité Terrain)**\n",
    "    * *Principe* : On vérifie si la valeur devinée est *réellement* la bonne en regardant le fichier original secret.\n",
    "    * *Sens* : Mesure la vulnérabilité réelle, \"Dieu voit tout\".\n",
    "\n",
    "* **Méthode B : Risque Théorique (Homogénéité) [NOUVEAU]**\n",
    "    * *Principe* : On regarde les groupes d'individus partageant les mêmes quasi-identifiants ($k$-anonymity groups). On calcule la diversité des maladies dans ces groupes.\n",
    "    * *Calcul* : Si dans un groupe de 3 personnes, tout le monde a le diabète, l'attaquant est sûr à 100% (Risque = 1). S'il y a 3 maladies différentes, il a 1 chance sur 3 (Risque = 0.33).\n",
    "    * *Sens* : Mesure la confiance de l'attaquant, sans avoir besoin de la vérité terrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FONCTIONS METRIQUES ---\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    \"\"\"Calcule le V de Cramer pour deux séries catégorielles.\"\"\"\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        return np.sqrt(phi2 / min(k-1, r-1)) if min(k-1, r-1) > 0 else 0\n",
    "\n",
    "def calculate_structure_score(df_ref, df_anon, method='spearman'):\n",
    "    \"\"\"Compare les matrices de corrélation (Spearman ou Cramer).\"\"\"\n",
    "    common_cols = [c for c in df_ref.columns if c in df_anon.columns and c != 'id_sejour']\n",
    "    if not common_cols: return 0.0\n",
    "    \n",
    "    # 1. Calcul des matrices\n",
    "    if method == 'spearman':\n",
    "        # Factorisation simple pour Spearman\n",
    "        df1 = df_ref[common_cols].apply(lambda x: pd.factorize(x)[0])\n",
    "        df2 = df_anon[common_cols].apply(lambda x: pd.factorize(x)[0])\n",
    "        mat1 = df1.corr(method='spearman').fillna(0)\n",
    "        mat2 = df2.corr(method='spearman').fillna(0)\n",
    "    \n",
    "    elif method == 'cramer':\n",
    "        # Calcul coûteux : on itère sur les paires\n",
    "        mat1 = pd.DataFrame(index=common_cols, columns=common_cols, dtype=float)\n",
    "        mat2 = pd.DataFrame(index=common_cols, columns=common_cols, dtype=float)\n",
    "        \n",
    "        # Pour optimiser, on prend un sous-ensemble si trop de colonnes, ou on fait le calcul complet\n",
    "        # Ici calcul complet simplifié\n",
    "        for c1 in common_cols:\n",
    "            for c2 in common_cols:\n",
    "                if c1 == c2: \n",
    "                    mat1.loc[c1, c2] = 1.0\n",
    "                    mat2.loc[c1, c2] = 1.0\n",
    "                else:\n",
    "                    # On calcule Cramer uniquement si ce n'est pas déjà fait (symétrie)\n",
    "                    if pd.isna(mat1.loc[c2, c1]):\n",
    "                        val1 = cramers_v(df_ref[c1], df_ref[c2])\n",
    "                        mat1.loc[c1, c2] = mat1.loc[c2, c1] = val1\n",
    "                        val2 = cramers_v(df_anon[c1], df_anon[c2])\n",
    "                        mat2.loc[c1, c2] = mat2.loc[c2, c1] = val2\n",
    "    \n",
    "    # 2. Comparaison (Différence Moyenne)\n",
    "    diff = (mat1 - mat2).abs().mean().mean()\n",
    "    # Score : 100% = structure identique, 0% = structure détruite\n",
    "    return max(0, (1 - diff * 2)) * 100\n",
    "\n",
    "def calculate_advanced_metrics(df_connaissance, df_publie, qi, sensitive_col, df_truth):\n",
    "    # --- 1. Corrélation (Benchmark) ---\n",
    "    corr_spearman = calculate_structure_score(df_connaissance, df_publie, method='spearman')\n",
    "    # Note: Cramer peut être lent sur grosses bases, on le fait ici pour la démonstration\n",
    "    corr_cramer = calculate_structure_score(df_connaissance, df_publie, method='cramer')\n",
    "\n",
    "    if any(c not in df_publie.columns for c in qi): return 0, 0, 0, corr_spearman, corr_cramer\n",
    "\n",
    "    # --- 2. Individualisation ---\n",
    "    # Groupement par QI\n",
    "    grouped = df_publie.groupby(qi)\n",
    "    counts = grouped.size()\n",
    "    unique_idx = counts[counts == 1].index\n",
    "    \n",
    "    # Taux d'individualisation (Réid)\n",
    "    df_pub_unique = df_publie.set_index(qi)\n",
    "    df_pub_unique = df_pub_unique[df_pub_unique.index.isin(unique_idx)].reset_index()\n",
    "    \n",
    "    merged = pd.merge(df_pub_unique, df_connaissance, on=qi, how='inner', suffixes=('_pub', '_know'))\n",
    "    \n",
    "    risk_reid = 0\n",
    "    if len(merged) > 0:\n",
    "        success = merged[merged['id_sejour_pub'] == merged['id_sejour_know']]\n",
    "        risk_reid = len(success) / len(df_publie) * 100\n",
    "\n",
    "    # --- 3. Inférence (Benchmark) ---\n",
    "    risk_inf_real = 0.0\n",
    "    risk_inf_theo = 0.0\n",
    "\n",
    "    if sensitive_col in df_publie.columns:\n",
    "        # A. Inférence Théorique (Perspective Attaquant)\n",
    "        # Pour chaque groupe (combinaison QI), quelle est la diversité de la variable sensible ?\n",
    "        # Risque = 1 / nombre_valeurs_uniques_dans_le_groupe\n",
    "        # On moyenne ce risque sur toute la population\n",
    "        def calc_group_risk(group):\n",
    "            n_unique = group[sensitive_col].nunique()\n",
    "            return 1 / n_unique\n",
    "        \n",
    "        # On applique sur tous les groupes (pas que les uniques)\n",
    "        group_risks = grouped.apply(calc_group_risk)\n",
    "        # On ré-étend ce risque à chaque individu\n",
    "        risk_inf_theo = df_publie.set_index(qi).join(group_risks.rename('risk'))['risk'].mean() * 100\n",
    "\n",
    "        # B. Inférence Réelle (Vérité Terrain)\n",
    "        if df_truth is not None and sensitive_col in df_truth.columns and len(merged) > 0:\n",
    "            col_pub = f\"{sensitive_col}_pub\" if f\"{sensitive_col}_pub\" in merged.columns else sensitive_col\n",
    "            try:\n",
    "                # Vérité pour les individus \"trouvés\" (merged)\n",
    "                true_vals = df_truth.loc[merged['id_sejour_know']][sensitive_col].values\n",
    "                obs_vals = merged[col_pub].values\n",
    "                risk_inf_real = np.sum(true_vals == obs_vals) / len(merged) * 100\n",
    "            except: pass\n",
    "            \n",
    "    return risk_reid, risk_inf_real, risk_inf_theo, corr_spearman, corr_cramer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exécution du Benchmark\n",
    "\n",
    "Comparaison des indicateurs sur les scénarios définis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = {\n",
    "    '1_Faible': [\"age10\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_y\",\"sortie_date_y\"],\n",
    "    '2_Moyen': [\"age5\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_ym\",\"sortie_date_ym\",\"specialite\",\"chirurgie\"],\n",
    "    '3_Fort': [\"age\",\"sexe\",\"entree_mode\",\"sortie_mode\",\"entree_date_ymd\",\"sortie_date_ymd\",\"specialite\",\"chirurgie\",\"diabete\",\"insuffisance_renale\",\"demence\"]\n",
    "}\n",
    "\n",
    "TARGET = 'liste_diag'\n",
    "results = []\n",
    "\n",
    "for name, df_var in datasets.items():\n",
    "    if name == 'reference': continue\n",
    "    \n",
    "    parts = name.split('_')\n",
    "    if len(parts) >= 3:\n",
    "        file_type = 'Direct' if 'direct' in name else 'Sample'\n",
    "        try: lvl = int(parts[-1])\n",
    "        except: lvl = 0\n",
    "    else: continue\n",
    "\n",
    "    for scen, cols in scenarios.items():\n",
    "        reid, inf_real, inf_theo, c_spear, c_cram = calculate_advanced_metrics(\n",
    "            df_reference, df_var, cols, TARGET, df_truth\n",
    "        )\n",
    "        results.append({\n",
    "            'Type': file_type, 'Mélange (%)': lvl, 'Scénario': scen,\n",
    "            'Individualisation': reid,\n",
    "            'Inférence (Réelle)': inf_real,\n",
    "            'Inférence (Théorique)': inf_theo,\n",
    "            'Corrélation (Spearman)': c_spear,\n",
    "            'Corrélation (Cramer)': c_cram\n",
    "        })\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "display(df_res.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisation des Benchmarks\n",
    "\n",
    "Nous affichons deux graphiques comparatifs pour mettre en évidence les différences méthodologiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_benchmarks(df):\n",
    "    if df.empty: return\n",
    "    \n",
    "    # On se concentre sur le type 'Direct' pour le benchmark des méthodes\n",
    "    df_plot = df[df['Type'] == 'Direct']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    # Graphique 1 : Benchmark Inférence (Réel vs Théorique)\n",
    "    # On prend le Scénario Moyen pour l'exemple\n",
    "    subset = df_plot[df_plot['Scénario'] == '2_Moyen']\n",
    "    axes[0].plot(subset['Mélange (%)'], subset['Inférence (Réelle)'], \n",
    "                 label='Succès Réel (Vérité Terrain)', marker='o', linewidth=2)\n",
    "    axes[0].plot(subset['Mélange (%)'], subset['Inférence (Théorique)'], \n",
    "                 label='Risque Théorique (Homogénéité)', marker='x', linestyle='--', linewidth=2)\n",
    "    axes[0].set_title(\"Benchmark Inférence : Réalité vs Estimation (Scénario Moyen)\")\n",
    "    axes[0].set_ylabel(\"%\")\n",
    "    axes[0].set_xlabel(\"Niveau de Mélange (%)`\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # Graphique 2 : Benchmark Corrélation (Spearman vs Cramer)\n",
    "    # Indépendant du scénario, on prend le premier bloc\n",
    "    subset_corr = df_plot[df_plot['Scénario'] == '1_Faible']\n",
    "    axes[1].plot(subset_corr['Mélange (%)'], subset_corr['Corrélation (Spearman)'], \n",
    "                 label='Spearman (Rang)', marker='o', color='purple')\n",
    "    axes[1].plot(subset_corr['Mélange (%)'], subset_corr['Corrélation (Cramer)'], \n",
    "                 label='Cramer V (Nominal)', marker='s', color='orange')\n",
    "    axes[1].set_title(\"Benchmark Corrélation : Impact du type de mesure\")\n",
    "    axes[1].set_ylabel(\"Conservation de la Structure (%)\")\n",
    "    axes[1].set_xlabel(\"Niveau de Mélange (%)`\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_benchmarks(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des Différences Méthodologiques\n",
    "\n",
    "1.  **Inférence (Réel vs Théorique)** :\n",
    "    * Le **Risque Théorique** (pointillés) reste souvent élevé même quand on mélange, car il se base sur la diversité apparente. Si le mélange crée des groupes homogènes par hasard, l'attaquant *croit* avoir réussi.\n",
    "    * Le **Succès Réel** (ligne pleine) chute brutalement. C'est la vraie protection : même si l'attaquant est confiant, le mélange a en réalité faussé la donnée sensible.\n",
    "    * *Conclusion* : Le mélange protège mieux que ce que l'attaquant peut estimer.\n",
    "\n",
    "2.  **Corrélation (Spearman vs Cramer)** :\n",
    "    * **Spearman** peut sous-estimer la perte de structure pour des variables purement nominales (Specialité) car il cherche un ordre qui n'existe pas.\n",
    "    * **Cramer's V** est plus robuste et montre généralement une chute plus fidèle de la qualité statistique globale de la base quand le mélange augmente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
